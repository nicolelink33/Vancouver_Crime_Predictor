% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Predicting type of crime from location and time information},
  pdfauthor={Zain Nofal, Tirth Joshi, Nicole Link},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Predicting type of crime from location and time information}
\author{Zain Nofal, Tirth Joshi, Nicole Link}
\date{2025-12-07}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}

\section{Summary}\label{summary}

In this project, we aim to predict what type of crime occurred in
Vancouver based on when and where it happened. We use a dataset from the
Vancouver Police Department with over 530,000 crime records from
2003-2017, covering 11 different crime types including theft, break-ins,
and vehicle collisions.

We tested three machine learning models: K-Nearest Neighbors, Support
Vector Machines, and Logistic Regression. After tuning, all three models
performed similarly, achieving around 62-64\% accuracy. While this isn't
perfect, it shows that time and location do provide some useful
information for predicting crime types, though there is clearly room for
improvement, possibly with additional features.

\section{Introduction}\label{introduction}

\subsection{Background}\label{background}

Crime prediction is an important tool for police departments trying to
figure out where to focus their resources. Vancouver, like most big
cities, has many different types of crime happening at different times
and places. If we can predict what kind of crime is likely to happen
based on patterns in the data, it could help with planning patrols and
prevention efforts.

\subsection{Research Question}\label{research-question}

Can we predict the type of crime based on when and where it happens?

We're comparing three different classification algorithms (K-NN, SVM,
and Logistic Regression) to see if this is possible, and which model
works best for this problem.

\section{Methods}\label{methods}

\subsection{Data}\label{data}

We're using the Vancouver Crime Dataset from Kaggle, which originally
came from the Vancouver Police Department (Osaku 2017). It has 530,652
crime records from 2003 to 2017, split into 11 crime types. The most
common is ``Theft from Vehicle'' (over 172,000 cases) and the rarest is
``Homicide'' (220 cases). We selected the four most common types of
crime, to ensure that all of our target classes have a sufficient number
of observations. The counts of these crimes in our training data are
shown in \textbf{?@fig-type\_dist}.
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../results/figures/crime_type_distribution.png}

Each record includes: - Time info: year, month, day, hour, minute -
Location info: neighborhood, street block, coordinates

There's some missing data - about 10\% of records don't have time
information and 11\% are missing neighborhood data. We filled in missing
times with the most common values and labeled missing neighborhoods as
``Unknown.''

\subsection{Analysis}\label{analysis}

We selected three models to use to build a classification model to
predict the crime type for each incident in the Vancouver crime dataset:
a k-Nearest Neighbors (k-NN) algorithm, a linear Support Vector Machine
(SVM) classifier, and a multinomial Logistic Regression model (LogReg).
For all tested models, all spatial, temporal, numeric, and categorical
features were included. The categorical variables were one-hot encoded,
and numeric variables were standardized using a column transformer
immediately before model fitting. The crime dataset was split using an
80/20 stratified train test split, in order to preserve class
proportions in both sets. A baseline model was created for each model
type, using the default hyperparameter values. Then, hyperparameter
optimization was performed on all models, using a 15,000-observation
stratified subset of the training data, in order to decrease
computational load. The best fit models found from these optimizations
were then scored on the test data set. The analysis was conducted in
Python using python, numpy, pandas, matplotlib, tqdm, and scikit-learn
Team (2020). The code used to perform this analysis is available at:
\url{https://github.com/nicolelink33/Vancouver_Crime_Predictor}.

\section{Results \& Discussion}\label{results-discussion}

\subsection{Model Performance}\label{model-performance}

\subsubsection{KNN}\label{knn}

The baseline k-NN model, using k = 5, achieved 58.8\% accuracy. After
hyperparameter optimization, the optimal value was found to be k = 85,
yielding a final accuracy of 0.51 on the test set. The hyperparameter
optimization results are shown in \textbf{?@fig-KNN\_opt}.
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../results/knn_k_optimization.png}
This model performed best on ``Theft from Vehicle'', while categories
such as ``Mischief'' and ``Break and Enter'' were more challenging. k-NN
model performance by crime type is shown in the produced confusion
matrix, shown in \textbf{?@fig-KNN\_cm}.
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../results/knn_confusion_matrix.png}

\subsubsection{SVM}\label{svm}

The baseline LinearSVC model with C = 1 achieved an accuracy of 0.5.
Results of the hyperparameter optimization search are shown in
\textbf{?@fig-SVM\_opt}. The selected model gave a final accuracy of 0.5
and an F1 score of 0.39, only slightly higher than the baseline,
indicating that model performance was not highly sensitive to the value
of C. The confusion matrix for the best fit linear SVM model is shown in
\textbf{?@fig-SVM\_cm}.
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../results/figures/svm_final_random_fit.png}
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../results/figures/svm_confusion_matrix.png}

\subsubsection{Logistic Regression}\label{logistic-regression}

The best fit logistic regression model achieved a test accuracy of
62.8\%, indicating slightly lower performance than KNN and SVM. The
confusion matrix for the best fit logistic regression model is shown in
\textbf{?@fig-LR\_cm}.
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../results/figures/logreg_confusion_matrix.png}

\subsection{Comparison}\label{comparison}

All three of our models gave quite similar accuracies: - Baseline K-NN:
\textasciitilde58\% - Optimized K-NN: 0.51 - Optimized SVM: 0.5 -
Logistic Regression: 62.8\%

The models did well on common crimes like ``Theft from Vehicle'' but
struggled with rarer or more ambiguous categories. We also noticed that
crime in Vancouver decreased from 2003 to 2011, then started increasing
again after 2012.

\section{Was This Expected?}\label{was-this-expected}

Somewhat! Crime classification is tough because different crime types
often happen in similar places at similar times. For example, various
types of theft might all peak at night in the same neighborhoods. We're
also only using time and location so we don't have info about weather,
economic conditions, or other factors that might matter.

The fact that all three algorithms performed similarly suggests the
limiting factor isn't the algorithm choice, but rather what we can
predict using only ``when'' and ``where'' information.

\subsection{Why This Matters}\label{why-this-matters}

Even with 64\% accuracy, these models could still be useful for helping
police decide where to patrol, understanding which crime types are more
predictable, showing that we need more features beyond just time and
location.

\section{Future Work}\label{future-work}

Going forward, to continue this project, we would like to try: - Add
more features like weather, day of week, proximity to bars/schools - Try
more advanced models like Random Forests or neural networks - Instead of
predicting exact crime type, predict severity level
(minor/moderate/serious) - Use more recent data (this dataset ends in
2017) - Apply techniques to handle the class imbalance problem

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-tqdm}
Costa-Luis, Casper da. 2019. {``Tqdm -- a Fast, Extensible Progress Bar
for Python and CLI.''} \url{https://github.com/tqdm/tqdm}.

\bibitem[\citeproctext]{ref-numpy}
Harris, Charles R., K. Jarrod Millman, StÃ©fan J. van der Walt, Ralf
Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020.
{``Array Programming with {NumPy}.''} \emph{Nature}.
\url{https://doi.org/10.1038/s41586-020-2649-2}.

\bibitem[\citeproctext]{ref-matplotlib}
Hunter, J. D. 2007. {``Matplotlib: A 2D Graphics Environment.''}
\emph{Computing in Science \& Engineering}.
\url{https://doi.org/10.1109/MCSE.2007.55}.

\bibitem[\citeproctext]{ref-CrimeKaggle}
Osaku, Wilian. 2017. {``{Crime in Vancouver}.''}
\url{https://www.kaggle.com/datasets/wosaku/crime-in-vancouver}.

\bibitem[\citeproctext]{ref-scikit-learn}
Pedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O.
Grisel, M. Blondel, et al. 2011. {``Scikit-Learn: Machine Learning in
{P}ython.''} \emph{Journal of Machine Learning Research} 12: 2825--30.

\bibitem[\citeproctext]{ref-click}
Team, Pallets. 2020. \emph{Click}.
\url{https://click.palletsprojects.com/}.

\bibitem[\citeproctext]{ref-pandas}
team, The pandas development. 2024. {``Pandas-Dev/Pandas: Pandas.''}
Zenodo. \url{https://doi.org/10.5281/zenodo.10537285}.

\bibitem[\citeproctext]{ref-python}
Van Rossum, Guido, and Fred L. Drake. 2009. \emph{Python 3 Reference
Manual}. Scotts Valley, CA: CreateSpace.

\end{CSLReferences}




\end{document}
